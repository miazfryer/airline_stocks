{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f297f32-1801-4c06-87a2-537b6d3fb8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the 'Close column \n",
    "data = df.filter(['Close'])\n",
    "# Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "# Get the number of rows to train the model on\n",
    "training_data_len = int(np.ceil( len(dataset) * .95 ))\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "train_data = scaled_data[0:int(training_data_len), :]\n",
    "# Split the data into x_train and y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "        \n",
    "# Convert the x_train and y_train to numpy arrays \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshape the data\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=1)\n",
    "\n",
    "# Create the testing data set\n",
    "# Create a new array containing scaled values from index 1543 to 2002 \n",
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "# Create the data sets x_test and y_test\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i, 0])\n",
    "    \n",
    "# Convert the data to a numpy array\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Reshape the data\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
    "\n",
    "# Get the models predicted price values \n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Get the root mean squared error (RMSE)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
    "\n",
    "# Plot the data\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predictions\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close', 'Predictions']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e0782-a49d-4f64-af66-591806ec0a9e",
   "metadata": {},
   "source": [
    "- Dense layer expects a vector as input\n",
    "- The LSTM network takes a 2D array as input.\n",
    "\n",
    "- return_sequences default = false(where only the last timestep cell emits signals. The output is, therefore, a vector.)\n",
    "- layer before RepeatVector(n_steps) needs return_sequences = false bcuz One layer of LSTM has as many cells as the timesteps.\n",
    "- The RepeatVector layer acts as a bridge between the encoder and decoder modules.\n",
    "- The TimeDistributed layer creates a vector of length equal to the number of features outputted from the previous layer. In this network, Layer 5 outputs 128 features. Therefore, the TimeDistributed layer creates a 128 long vector and duplicates it 2 (= n_features) times.\n",
    "- return_sequences=True for the layer before the timedistributed layer\n",
    "- The Decoder layer is designed to unfold the encoding.Therefore, the Decoder layers are stacked in the reverse order of the Encoder.\n",
    "> model\n",
    "- model = Sequential()\n",
    "- model.add(LSTM(128, activation='relu', input_shape=(timesteps,n_features), return_sequences=True))\n",
    "- model.add(LSTM(64, activation='relu', return_sequences=False))\n",
    "- model.add(RepeatVector(timesteps))\n",
    "- model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "- model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "- model.add(TimeDistributed(Dense(n_features)))\n",
    "- model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da2c38-a4f0-4d8b-b22b-5d4728320d42",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ways to read in files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e29f61-bf37-484b-bcb7-48372ba1020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('Data/Stocks/')\n",
    "list = os.listdir()\n",
    "number_files = len(list)\n",
    "print(number_files)\n",
    "\n",
    "company_name = ['luv.us.txt','dal.us.txt', 'aal.us.txt', 'ual.us.txt']\n",
    "\n",
    "data = []\n",
    "for filename in company_name:\n",
    "    df = pd.read_csv(os.path.join('',filename), sep=',')\n",
    "    label, _, _ = filename.split(sep='.')\n",
    "    df['Label'] = label\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    data.append(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
